FROM continuumio/miniconda3:4.6.14

LABEL maintainer="Andrew Che <andrew@neuraldev.io>"

# This is the base image for both a Dask Scheduler and a Dask Worker.
# The scheduler should only contain 1 container.
# It is possible to replicate and scale the Dask Worker to allow better
# distributed processing.
# To scale on build/run: docker-compose up --scale dask-worker=2
# To scale after run: docker-compose scale dask-worker=2

# Reference:
# https://github.com/dask/dask-docker
# https://docs.dask.org/en/latest/setup/docker.html

# note: Ensure you install all required dependencies if the processing from other
# containers rely on those packages.
RUN conda install --yes --freeze-installed -q \
    -c anaconda \
    python==3.7.3 \
    python-blosc \
    cytoolz \
    dask==2.3.0 \
    nomkl \
    numpy==1.16.4 \
    pandas==0.25.0 \
    && conda clean -tipsy \
    && find /opt/conda/ -type f,l -name '*.a' -delete \
    && find /opt/conda/ -type f,l -name '*.pyc' -delete \
    && find /opt/conda/ -type f,l -name '*.js.map' -delete \
    && find /opt/conda/lib/python*/site-packages/bokeh/server/static -type f,l -name '*.js' -not -name '*.min.js' -delete \
    && rm -rf /opt/conda/pkgs

RUN mkdir /opt/app
RUN mkdir /opt/app/Simulation
RUN mkdir /opt/app/Logger
WORKDIR /opt/app

COPY ./simulation /opt/app/Simulation/simulation

COPY ./setup.py /opt/app/Simulation/

WORKDIR /opt/app/Logger
RUN python setup.py install
WORKDIR /opt/app/Simulation
RUN python setup.py install

# install our arc_logging library
WORKDIR /opt/app/arc_logging
RUN python setup.py install

WORKDIR /opt/app

# The prepare.sh script allows you to add additional dependencies.
# If needed, also install tini==0.18.0.
#ENTRYPOINT ["tini", "-g", "--", "/usr/bin/prepare.sh"]

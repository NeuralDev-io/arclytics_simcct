
version: '3.7'

services:

  fluentd:
    build:
      context: ./services/fluentd
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "fluentd"
    image: neuraldev/arc_fluentd:1.0
    restart: always
    ports:
      - 24224:24224
      - 24224:24224/udp
      - 9880:9880
    expose:
      - 24224
      - 9880
    volumes:
      - ./services/fluentd/logs:/fluentd/log
    depends_on:
      - elasticsearch
    networks:
      - host

  client:
    build:
      context: ./services/client
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "client"
    image: neuraldev/arc_sim_client:1.1
    volumes:
      - ./services/client:/usr/src/app
      - /usr/src/app/node_modules
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: client.docker.access
    ports:
      - 3000:3000
    expose:
      - 3000
    environment:
      - NODE_ENV=development
      - REACT_APP_SIM_HOST=http://localhost
      - REACT_APP_SIM_PORT=8000
    depends_on:
      - mongodb
      - simcct
      - fluentd
    networks:
      - host

  nginx:
    build:
      context: ./services/nginx
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "simcct"
    labels:
      arclytics.io: "development"
    image: neuraldev/arc_sim_nginx:1.0
    restart: always
    ports:
      - 80:80
    depends_on:
      - simcct
      - client
    networks:
      - host

  simcct:
    build:
      context: ./services/simcct
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "simcct"
    image: neuraldev/arc_sim_service:1.1
    volumes:
      - ./services/simcct:/usr/src/app  # This is a bind mount
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: simcct.docker.access
    ports:
      - 8000:8000
    expose:
      - 8000
    environment:
      - FLASK_APP=sim_api/app.py
      - FLASK_ENV=development
      - APP_SETTINGS=configs.flask_conf.DevelopmentConfig
      - SECRET_KEY=${SECRET_KEY}
      - SECURITY_PASSWORD_SALT=${SECURITY_PASSWORD_SALT}
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_APP_DB=arc_dev
      - MONGO_APP_USER=${MONGO_APP_USER}
      - MONGO_APP_USER_PASSWORD=${MONGO_APP_USER_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - MAIL_SERVER=${MAIL_SERVER}
      - MAIL_PORT=${MAIL_PORT}
      - MAIL_USE_TLS=${MAIL_USE_TLS}
      - MAIL_USERNAME=${MAIL_USERNAME}
      - MAIL_PASSWORD=${MAIL_PASSWORD}
      - CLIENT_PROTOCOL=http
      - CLIENT_HOST=localhost
      - CLIENT_PORT=80
      - DASK_SCHEDULER_ADDRESS=tcp://dask-scheduler:8786
      - FLUENTD_HOST=fluentd
      - FLUENTD_PORT=24224
      - ELASTIC_APM_SERVER_URL=http://apm-server:8200
    depends_on:
      - mongodb
      - redis
      - fluentd
      - elasticsearch
      - apm-server
    networks:
      - host

  arclytics:
    build:
      context: ./services/arclytics
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "arclytics"
    image: neuraldev/arclytics_service:1.3
    volumes:
      - ./services/arclytics:/usr/src/app
    ports:
      - 8001:8001
    expose:
      - 8001
    environment:
      - FLASK_APP=arc_api/__init__.py
      - FLASK_ENV=development
      - APP_SETTINGS=configs.flask_conf.DevelopmentConfig
      - SECRET_KEY=${SECRET_KEY}
      - SECURITY_PASSWORD_SALT=${SECURITY_PASSWORD_SALT}
    networks:
      - host

  celery-worker:
    build:
      context: ./services/celery-worker
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "celery-worker"
    image: neuraldev/arc_sim_celery:1.0
    volumes:
      - ./services/celery-worker:/usr/src/app
    ports:
      - 5555:5555  # Flower Web GUI management of Celery
    expose:
      - 5555
    environment:
      - C_FORCE_ROOT=true
      - FLASK_ENV=development
      - APP_SETTINGS=flask_conf.DevelopmentConfig
      - MAIL_SERVER=${MAIL_SERVER}
      - MAIL_PORT=${MAIL_PORT}
      - MAIL_USE_TLS=${MAIL_USE_TLS}
      - MAIL_USERNAME=${MAIL_USERNAME}
      - MAIL_PASSWORD=${MAIL_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    networks:
      - host

  redis:
    build:
      context: ./services/redis
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "redis"
    image: neuraldev/arc_sim_redis:1.1
    restart: always
    ports:
      - 6379:6379
    expose:
      - 6379
    networks:
      - host

  mongodb:
    build:
      context: ./services/db
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "mongodb"
    image: neuraldev/arc_sim_mongo:1.1
    restart: always
    volumes:
      - ./services/db/test_data:/data/test
    ports:
      - 27017:27017
    expose:
      - 27017
    environment:
      - MONGO_DATA_DIR=/usr/data/db
      - MONGO_LOG_DIR=/dev/null
    networks:
      - host

  elasticsearch:
    build:
      context: ./services/elasticsearch
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "elasticsearch"
    image: neuraldev/arc_elasticsearch:latest
    volumes:
      - ./services/elasticsearch/data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    expose:
      - 9200
      - 9300
    environment:
      - discovery.type=single-node
      - cluster.name=arc-sim-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - host

  apm-server:
    build:
      context: ./services/apm-server
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "apm-server"
    image: neuraldev/arc_apm_server:latest
    ports:
      - 8200:8200
    expose:
      - 8200
    volumes:
      - ./services/apm-server/apm-server.docker.yml:/usr/share/apm-server/apm-server.yml
    depends_on:
      - elasticsearch
    networks:
      - host

  kibana:
    build:
      context: ./services/kibana
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "kibana"
    image: neuraldev/arc_kibana:latest
    ports:
      - 5601:5601
    expose:
      - 5601
    volumes:
      - ./services/kibana/kibana.yaml:/user/share/kibana/config/kibana.yaml
    depends_on:
      - elasticsearch
      - fluentd
    networks:
      - host

  swagger:
    build:
      context: ./services/swagger
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "swagger"
    image: neuraldev/arc_sim_swagger:1.0
    ports:
      - 3001:8080  # expose ports - HOST:CONTAINER
    expose:
      - 3001
    environment:
      - URL=swagger.yaml
    networks:
      - host

  dask-scheduler:
    build:
      context: ./services/dask
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
        service: "dask-scheduler"
    image: neuraldev/arc_dask_scheduler:1.0
    hostname: dask-scheduler
    ports:
      - 8786:8786
      - 8787:8787
    expose:
      - 8786
      - 8787
    # Entrypoint command needs to be set here because Dockerfile shared with `dask-worker`
    command: ['dask-scheduler']
    networks:
      - host

  dask-worker:
    build:
      context: ./services/simcct
      dockerfile: Dockerfile-worker
      labels:
        arclytics.io: "development"
        service: "dask-worker"
    image: neuraldev/arc_dask_worker:1.0
    hostname: dask-worker
    command: ['dask-worker', 'tcp://dask-scheduler:8786', '--no-nanny']
    networks:
      - host

  jupyter:
    build:
      context: ./services/jupyter
      dockerfile: Dockerfile
      labels:
        arclytics.io: "development"
    image: neuraldev/arc_dask_notebook:1.0
    domainname: io.arclytics.app
    hostname: jupyter
    volumes:
      - type: bind
        source: ./services/jupyter/notebooks
        target: /home/arclytics/
    ports:
      - 8888:8888
    expose:
      - 8888
    environment:
      - NB_USER=arclytics
      - DASK_SCHEDULER_ADDRESS=tcp://dask-scheduler:8786
    depends_on:
      - dask-scheduler
      - dask-worker
    networks:
      - host


  # ============================== # TEST MICROSERVICES # ============================== #
  # Both these services were created for testing purposes and a proof-of-concept for
  # the use of `fluentd` as the logging driver for Docker. They are not to be used
  # in any production environment as they are not configured at all.
  # =================================================================================== #
  fluent-python:
    build:
      context: ./services/fluent-python
      dockerfile: Dockerfile
      labels:
        arclytics.io: "concept"
    image: neuraldev/arc_fluent_python:1.0
    ports:
      - 5005:5000
    expose:
      - 5005
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: fluent-python.access
    environment:
      - FLUENT_HOST=fluentd
    depends_on:
      - fluentd
    networks:
      - host

  fluent-react:
    build:
      context: ./services/fluent-react
      dockerfile: Dockerfile
      labels:
        arclytics.io: "concept"
    image: neuraldev/arc_fluent_react:1.0
    ports:
      - 80:80
    expose:
      - 80
    logging:
      driver: fluentd
      options:
        fluentd-address: localhost:24224
        tag: fluent-react.access
    depends_on:
      - fluentd
    networks:
      - host
  # =================================================================================== #

networks:
  host:
    driver: bridge
    labels:
      arclytics.io: "development"

# https://docs.docker.com/compose/compose-file/#volume-configuration-reference
#  DECISION:
#  This is not working as a dir needs to be created before binding the mount.
#  Since Docker creates a Volume in /var/lib/docker/volumes/vol_name/_data
#  which is an abstraction layer that gets bound to the Docker container.
#  We prefer to use bind mounts in development so that we can easily destroy
#  data quickly and bring up new ones using scripts for MongoDB and Redis.
#
#volumes:
#  arclytics_dir:
#    labels:
#      arclytics.io: "development"
#    driver: local
#    driver_opts:
#      device: "./services/users"
#      type: none
#      o: bind
